from datetime import datetime
from pandas import json_normalize
from tabulate import tabulate
from termcolor import colored

import ast
import ipaddress
import json
import luigi
import os
import pandas as pd
import requests
import subprocess
import time

from tpahelper.base import BaseTask, get_output_path
from tpahelper.config import config
from tpahelper.utils.external_commands import (
    otx_ipv4,
    otx_ipv6,
    tcpdump_protocol
)
from tpahelper.utils.html_templates import datatable_template
from tpahelper.utils.protocols import ndpi_protocol_map as proto_map
from tpahelper.utils.protocols import processor_map





def safe_eval(x):
    try:
        return ast.literal_eval(x)
    except (ValueError, SyntaxError):
        return x  # return as is if it's not a list string


class RunNdpiReader(BaseTask):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.pcap_name = str(self.pcap_file).split('/')[-1]
        self.pcap_path = os.path.abspath(self.pcap_file)
        self.output_path = get_output_path(self)
        self.summary_file = os.path.join(self.output_path, f"ndpi_summary.txt")
        self.flows_file = os.path.join(self.output_path, f"ndpi_flows.json")

    def output(self):
        return {
            'summary': luigi.LocalTarget(self.summary_file),
            'flows': luigi.LocalTarget(self.flows_file)
        }

    def run(self):
        print(colored("Task started: RunNdpiReader", "green"))
        # Create output directory
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(self.output_path, exist_ok=True)

        # Execute ndpiReader with output handled by Python
        result = subprocess.run(["ndpiReader", "-i", self.pcap_path, "-K", "json", "-k", self.flows_file],
                                capture_output=True,
                                text=True)

        with open(self.summary_file, 'w') as summary_out:
            summary_out.write(result.stdout)


class NdpiFlowsToDataFrame(BaseTask):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.pcap_name = str(self.pcap_file).split('/')[-1]
        self.output_path = get_output_path(self)
        self.flows_parquet = os.path.join(self.output_path, "ndpi_flows.parquet")

    def requires(self):
        return RunNdpiReader(**self.param_dict())

    def output(self):
        return luigi.LocalTarget(self.flows_parquet)

    def run(self):
        print(colored("Task started: NdpiFlowsToDataFrame", "green"))
        # Accessing files generated by RunNdpiReader
        input_files = self.input()
        flows_file_path = input_files['flows'].path
        df = pd.read_json(flows_file_path, lines=True)

        # Explode dict values in columns to separate columns
        explode_columns = ['xfer', 'iat', 'pktlen', 'tcp_flags']
        for col in explode_columns:
            if col in df.columns:
                expanded_df = df[col].apply(pd.Series)
                expanded_df.columns = [f"{col}_{c}" for c in expanded_df.columns]
                df = df.join(expanded_df)

        # Drop the original columns
        df.drop(columns=explode_columns, inplace=True)
        df = df.fillna('-')

        # Convert milliseconds to UTC datetime
        df["first_seen_utc"] = pd.to_datetime(df["first_seen_ms"], unit="ms", utc=True)
        df["last_seen_utc"] = pd.to_datetime(df["last_seen_ms"], unit="ms", utc=True)

        # Convert l7_protocol_data to string.
        # required to deal with limitations of parquet file format
        if 'l7_protocol_data' in df.columns:
            df['l7_protocol_data'] = df['l7_protocol_data'].apply(str)

        # Write the dataframe to parquet file
        df.to_parquet(self.flows_parquet)

class FlowsDataFrameToHTML(BaseTask):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        print(f"Initializing with pcap_file: {self.pcap_file}")
        self.output_path = get_output_path(self)
        self.flows_html = os.path.join(self.output_path, "flows.html")
        self.pcap_name = str(self.pcap_file).split('/')[-1]

    def requires(self):
        return NdpiFlowsToDataFrame(**self.param_dict())

    def output(self):
        return luigi.LocalTarget(self.flows_html)

    def run(self):
        print(colored("Task started: FLowsDataFrameToHTML", "green"))
        # Accessing files generated by NdpiFlowsToDataFrame
        input_files = self.input()
        flows_file_path = input_files.path

        df = pd.read_parquet(flows_file_path)

        # Convert DataFrame to HTML
        html_table = df.to_html(classes='display', index=False, table_id='dataTable')

        page = datatable_template.format(html_table)

        with self.output().open('w') as out_file:
            out_file.write(page)


class PublicIPsfromFlowsDataFrame(BaseTask):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.pcap_name = str(self.pcap_file).split('/')[-1]
        self.output_path = os.path.join(self.output_dir, self.pcap_name.replace('.pcap', ''))
        self.public_ips_file = os.path.join(self.output_path, f"public_ips.txt")

    def requires(self):
        return NdpiFlowsToDataFrame(**self.param_dict())

    def output(self):
        return luigi.LocalTarget(self.public_ips_file)

    def run(self):
        print(colored("Task started: PublicIPsfromFlowsDataFrame", "green"))
        # Accessing files generated by NdpiFlowsToDataFrame
        input_files = self.input()
        flows_file_path = input_files.path

        df = pd.read_parquet(flows_file_path)
        public_ips = [ip for ip in df['src_name'].unique()
                      if not ipaddress.ip_address(ip).is_private
                      and not ipaddress.ip_address(ip).is_reserved
                      and not ipaddress.ip_address(ip).is_link_local
                      and not ipaddress.ip_address(ip).is_loopback
                      and not ipaddress.ip_address(ip).is_multicast]

        public_ips += [ip for ip in df['dst_name'].unique()
                      if not ipaddress.ip_address(ip).is_private
                      and not ipaddress.ip_address(ip).is_reserved
                      and not ipaddress.ip_address(ip).is_link_local
                      and not ipaddress.ip_address(ip).is_loopback
                      and not ipaddress.ip_address(ip).is_multicast]


        with self.output().open('w') as out_file:
            for ip in public_ips:
                out_file.write(f"{ip}\n")
            else:
                out_file.write("")

        print(colored(f"Public IPs written to {self.public_ips_file}", "green"))
        print(colored(f"Public IPs: {public_ips}", "green"))


class QueryOTX(BaseTask):
    indicator = luigi.Parameter()
    indicator_type = luigi.Parameter()
    output_file = luigi.Parameter()

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    def output(self):
        return luigi.LocalTarget(self.output_file)

    def run(self):
        print(colored(f"Task started: QueryOTX, Indicator: {self.indicator}", "green"))
        otx_url = None
        if self.indicator_type == "ipv4":
            otx_url = otx_ipv4
        elif self.indicator_type == "ipv6":
            otx_url = otx_ipv6

        # Query OTX for the indicator
        if otx_url:
            resp = requests.get(otx_url.format(self.indicator))
            if resp.status_code == 200:
                otx_data = resp.json()
            else:
                otx_data = {'error': 'Failed to fetch data', 'indicator': self.indicator}
        else:
            otx_data = {'error': 'Invalid indicator type', 'indicator': self.indicator}

        print(colored(f"OTX results stored in {self.output_file}", "green"))
        with self.output().open('w') as out_file:
            json.dump(otx_data, out_file)

class IPReputation(BaseTask):
    # Define retry parameters
    retry_count = 3  # Number of retries
    retry_delay = 300  # Delay between retries in seconds (optional)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.out_dir = self.task_output_path("indicators")
        self.raw_dir = self.task_output_path("indicators/raw")
        self.retry_count = 10
        self.retry_delay = 15
        self.ipv4 = []
        self.ipv6 = []
        self.return_values = []

    def requires(self):
        return PublicIPsfromFlowsDataFrame(**self.param_dict())

    def output(self):
        default_output = os.path.join(self.out_dir, "IPReputation_complete.txt")
        return [luigi.LocalTarget(default_output)] + self.return_values

    def get_public_ips(self):
        with open(self.input().path, 'r') as infile:
            ips = infile.readlines()

        self.ipv4 = list(set(ip.strip() for ip in ips if ipaddress.ip_address(ip.strip()).version == 4))
        self.ipv6 = list(set(ip.strip() for ip in ips if ipaddress.ip_address(ip.strip()).version == 6))

        # define the output values
        self.return_values += [luigi.LocalTarget(os.path.join(self.raw_dir, f"otx_ipv4_{ip}.json")) for ip in self.ipv4]
        self.return_values += [luigi.LocalTarget(os.path.join(self.raw_dir, f"otx_ipv6_{ip}.json")) for ip in self.ipv6]

    def run(self):
        print(colored("Task started: IPReputation", "green"))
        print(colored(f"IPs to process: {self.ipv4}, {self.ipv6}", "green"))
        # create output directory
        os.makedirs(self.out_dir, exist_ok=True)
        os.makedirs(self.raw_dir, exist_ok=True)

        # call QueryOTX with ipv4_ips and ipv6_ips separately
        query_tasks = []  # List to store all QueryOTX tasks

        self.get_public_ips()

        if self.ipv4:
            print(colored(f"Querying OTX for {len(self.ipv4)} IPv4 addresses", "green"))
            indicator_type = "ipv4"
            for indicator in self.ipv4:
                output_file = os.path.join(self.raw_dir, f"otx_{indicator_type}_{indicator}.json")
                query_task = QueryOTX(pcap_file=self.pcap_file, indicator=indicator,
                                      indicator_type=indicator_type, output_file=output_file)
                query_tasks.append(query_task)
                yield query_task

        if self.ipv6:
            print(colored(f"Querying OTX for {len(self.ipv6)} IPv6 addresses", "green"))
            indicator_type = "ipv6"
            for indicator in self.ipv6:
                output_file = os.path.join(self.raw_dir, f"otx_{indicator_type}_{indicator}.json")
                query_task = QueryOTX(pcap_file=self.pcap_file, indicator=indicator,
                                      indicator_type=indicator_type, output_file=output_file)
                query_tasks.append(query_task)
                yield query_task

        if not query_tasks:  # If there are no QueryOTX tasks, exit early
            print(colored("No public IPs found", "yellow"))
        else:
            # Wait for all QueryOTX tasks to complete
            yield query_tasks

        # Store completion time in marker file
        with open(self.output()[0].path, 'w') as marker_file:
            marker_file.write(datetime.now().isoformat())


class SummarizeIPReputation(BaseTask):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # self.output_path = os.path.join(get_output_path(self), "indicators")
        self.out_dir = self.task_output_path("indicators")
        self.out_parquet = os.path.join(self.out_dir, "ip_reputation.parquet")
        self.out_html = os.path.join(self.out_dir, "ip_reputation.html")

    def requires(self):
        return IPReputation(**self.param_dict())

    def output(self):
        return [luigi.LocalTarget(self.out_parquet), luigi.LocalTarget(self.out_html)]

    def run(self):
        # create output directory
        print(colored("Task started: SummarizeIPReputation", "green"))
        os.makedirs(self.out_dir, exist_ok=True)

        # Accessing files generated by IPReputation
        input_files = list(input_file.path for input_file in self.input())
        if len(input_files) == 1:
            print(colored("No IPs to process", "yellow"))
            # create empty parquet file and blank html page
            pd.DataFrame().to_parquet(self.out_parquet)
            with open(self.out_html, 'w') as out_file:
                out_file.write(datatable_template.format(''))

            return

        # Skip the marker file
        input_files = input_files[1:] if len(input_files) > 1 else []
        otx_files = [f for f in input_files]

        # Initialize an empty DataFrame for the main data and pulses
        main_df_list = []
        pulses_df_list = []

        # Read each file and process
        for file in otx_files:
            with open(file, 'r') as infile:
                data = json.load(infile)

                # Normalize main data, excluding the deeply nested 'pulses' first
                this_df = json_normalize(data)
                if 'pulse_info.pulses' in this_df.columns:
                    this_df.drop(columns=['pulse_info.pulses'], inplace=True)

                # Store each main DataFrame to list
                main_df_list.append(this_df)

                # Check if 'pulse_info.pulses' is present and process if available
                if 'pulse_info.pulses' in data:
                    # Normalize pulses data
                    pulses = json_normalize(data, record_path=['pulse_info', 'pulses'])
                    # Add an identifier if necessary (e.g., from the main data)
                    if 'indicator' in this_df.columns:
                        pulses['indicator'] = data['indicator']
                    pulses_df_list.append(pulses)

        # Concatenate all main dataframes into a single DataFrame
        main_df = pd.concat(main_df_list, ignore_index=True, sort=False)

        # Concatenate all pulses dataframes into a single DataFrame
        if pulses_df_list:
            pulses_df = pd.concat(pulses_df_list, ignore_index=True, sort=False)

            # Join pulses to the main DataFrame based on an identifier or directly if the order is preserved
            # Here we assume 'indicator' to be the linking column; adjust as necessary
            df = pd.merge(main_df, pulses_df, on='indicator', how='left', suffixes=('', '_pulse'))
        else:
            df = main_df  # No pulses data to merge

        # Write the DataFrame to parquet file
        df.to_parquet(self.out_parquet)
        html_table = df.to_html(classes='display', index=False, table_id='dataTable')

        page = datatable_template.format(html_table)
        with open(self.out_html, 'w') as out_file:
            out_file.write(page)


class ExtractProtocol(BaseTask):
    output_pcap = luigi.Parameter()
    filters = luigi.DictParameter()

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.protocol_dir = os.path.join(get_output_path(self), "protocols")

    def output(self):
        return luigi.LocalTarget(self.output_pcap)

    def run(self):
        print(colored("Task started: ExtractProtocol", "green"))
        print(colored(f"Filters: {self.filters}", "green"))
        os.makedirs(self.protocol_dir, exist_ok=True)

        command = tcpdump_protocol.format(self.pcap_file, self.output_pcap, self.filters.get('tcpdump'))

        # Extract packets from pcap file based on protocol
        result = subprocess.run(command.split(),
                                capture_output=True,
                                text=True)


class SegmentProtocols(BaseTask):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.output_path = get_output_path(self)
        self.protocols_dir = os.path.join(self.output_path, "protocols")
        self.protocol_pcaps_dir = os.path.join(self.protocols_dir, "pcaps")
        self.pcap_name = str(self.pcap_file).split('/')[-1]
        self.to_extract = []
        self.output_pcaps = []
        self.marker_file = os.path.join(self.output_path, "SegmentProtocols_complete.txt")

    def requires(self):
        return NdpiFlowsToDataFrame(**self.param_dict())

    def output(self):
        return [luigi.LocalTarget(self.marker_file)] + self.output_pcaps

    def run(self):
        print(colored("Task started: SegmentProtocols", "green"))
        # create protocols directory
        os.makedirs(self.protocol_pcaps_dir, exist_ok=True)

        # load flows dataframe
        flows_df = pd.read_parquet(self.input().path)

        # get unique l7_protocol_name values and their corresponding src_port and dst_port
        protocols = flows_df['l7_protocol_name'].unique()
        l7_protocols_ports = flows_df.groupby('l7_protocol_name').agg({'src_port': 'unique', 'dst_port': 'unique'}).reset_index()

        summary_csv = []

        for protocol in protocols:
            proto_dict = proto_map.get(protocol, None)
            if proto_dict:
                tcpdump = proto_dict.get('tcpdump', None)
                known_ports = proto_dict.get('ports', None)
                if tcpdump and known_ports:
                    # check if any of the ports in proto_dict['ports'] are present in
                    # l7_protocols_ports['src_port'] or l7_protocols_ports['dst_port']
                    # if so, add the protocol to the list of protocols to extract
                    src_ports = l7_protocols_ports.loc[
                                    l7_protocols_ports['l7_protocol_name'
                                ] == protocol, 'src_port'].values[0]

                    dst_ports = l7_protocols_ports.loc[
                                    l7_protocols_ports['l7_protocol_name'
                                ] == protocol, 'dst_port'].values[0]

                    if (any([port in src_ports for port in proto_dict['ports']])
                            or any([port in dst_ports for port in proto_dict['ports']])
                            or proto_dict['ports'] == ['*']):
                        self.to_extract.append((protocol, proto_dict))
                    else:
                        summary_csv.append((protocol, "port-issue", None))
            else:
                summary_csv.append((protocol, "unhandled", None))

        # extract protocols
        for proto_tuple in self.to_extract:
            output_pcap = os.path.join(self.protocol_pcaps_dir, f"{self.pcap_name}_{proto_tuple[0]}.pcap")
            self.output_pcaps.append(luigi.LocalTarget(output_pcap))
            yield ExtractProtocol(pcap_file=self.pcap_file, output_pcap=output_pcap, filters=proto_tuple[1])

        with open(self.marker_file, 'w') as f:
            f.write("ProcessProtocols task completed successfully.\n")


class ExtractStrings(BaseTask):
    protocol_pcap = luigi.Parameter()

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.proto_strings_dir = os.path.join(get_output_path(self), "protocols", "strings")
        self.output_filename = str(self.protocol_pcap).split('_')[-1].replace('.pcap', '') + "_strings.txt"
        self.output_filepath = os.path.join(self.proto_strings_dir, self.output_filename)

    def output(self):
        return luigi.LocalTarget(self.output_filepath)

    def run(self):
        print(colored(f"Dumping strings: {self.output_filename}", "green"))
        # create strings directory
        os.makedirs(self.proto_strings_dir, exist_ok=True)

        command = f"strictstrings -q {self.protocol_pcap} > {self.output_filepath}"
        print(colored(f'Executing command: {command}', 'yellow'))

        result = subprocess.run(command, shell=True, capture_output=True, text=True)


class ExtractProtocolValues(BaseTask):
    protocol_pcap = luigi.Parameter()

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.protocol_values_dir = os.path.join(get_output_path(self), "protocols", "values")
        self.output_filename = str(self.protocol_pcap).split('_')[-1].replace('.pcap', '') + "_values.txt"
        self.output_filepath = os.path.join(self.protocol_values_dir, self.output_filename)
        self.protocol = str(self.protocol_pcap).split('_')[-1].replace('.pcap', '')
        self.output_files = []

    def output(self):
        return [luigi.LocalTarget(f) for f in self.output_files]

    def run(self):
        print(colored("Task started: ExtractProtocolValues", "green"))
        # create values directory
        os.makedirs(self.protocol_values_dir, exist_ok=True)

        cls = processor_map.get(self.protocol.lower(), None)
        if cls:
            processor = cls(self.protocol_pcap, self.protocol_values_dir)
            print(colored(f"Running processor {processor.name} for: {self.protocol_pcap}", "green"))
            self.output_files = processor.run()
            print(colored(f"Output files: {self.output_files}", "green"))

        else:
            print(colored(f"No processor found for {self.protocol}", "red"))

class ProcessProtocols(BaseTask):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.protocol_tasks = []
        self.marker_file = os.path.join(self.output_path(), "ProcessProtocols_complete.txt")  # Add this line

    def requires(self):
        return SegmentProtocols(**self.param_dict())

    def run(self):
        print(colored("Task started: ProcessProtocols", "green"))
        for target in self.input():
            protocol = str(target.path).split('_')[-1].replace('.pcap', '')
            self.protocol_tasks.append(ExtractStrings(pcap_file=self.pcap_file, protocol_pcap=target.path))

            if protocol.lower() in processor_map:
                self.protocol_tasks.append(ExtractProtocolValues(pcap_file=self.pcap_file, protocol_pcap=target.path))

        yield self.protocol_tasks

        # Write to the marker file when all tasks are complete
        with open(self.marker_file, 'w') as f:
            f.write("ProcessProtocols task completed successfully.\n")

    def output(self):
        outputs = [luigi.LocalTarget(self.marker_file)]  # Add this line
        for task in self.protocol_tasks:
            print(colored(f"Output: {task.output()}", "green"))
            if isinstance(task.output(), list):
                for f in task.output():
                    outputs.append(luigi.LocalTarget(f.path))
            else:
                outputs.append(luigi.LocalTarget(task.output().path))

        return outputs


class AllTasks(BaseTask):
    def requires(self):
        return [
            PublicIPsfromFlowsDataFrame(**self.param_dict()),
            FlowsDataFrameToHTML(**self.param_dict()),
            ProcessProtocols(**self.param_dict()),
            SummarizeIPReputation(**self.param_dict()),
        ]

    def run(self):
        print(colored("Task started: AllTasks", "green"))
        # Assume all tasks are completed successfully if run() is executed
        try:
            # Delete the "did_not_complete.txt" file if it exists
            if os.path.exists(self.output()['failure'].path):
                os.remove(self.output()['failure'].path)

            # Write to the success target
            with self.output()['success'].open('w') as f:
                f.write("All tasks completed successfully.\n")
            print(colored("AllTasks completed", "green"))
        except Exception as e:
            # If an exception occurs, write to the failure target
            with self.output()['failure'].open('w') as f:
                f.write(f"All tasks did not complete successfully. Error: {str(e)}\n")
            print(colored("Error occurred", "red"))
            raise  # Re-raise the exception to ensure Luigi handles the failure correctly

    def output(self):
        return {
            'success': luigi.LocalTarget(os.path.join(self.output_path(), "all_tasks_complete.txt")),
            'failure': luigi.LocalTarget(os.path.join(self.output_path(), "did_not_complete.txt")),
        }

    def on_success(self):
        print(colored(f"Task {self.task_id} succeeded",  "green"))
        # write timestamp to the success output file:
        with self.output()['success'].open('w') as f:
            f.write(f"Task succeeded at {datetime.now().isoformat()}\n")

    def on_failure(self, exception):
        print(colored(f"Task {self.task_id} failed with exception: {exception}", "red"))
        # write timestamp to the failure output file:
        with self.output()['failure'].open('w') as f:
            f.write(f"Task failed at {datetime.now().isoformat()}\n{str(exception)}\n")
        raise exception
